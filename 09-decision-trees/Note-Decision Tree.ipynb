{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "$\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "So far, we have examined parameteric methods--from the given input and output, we learn the parameters that map between them with minimum loss. Decision tree is a good example for *nonparametric* method. A decition tree is a hierarchical data structure that implements the divide-and-conquer strategy (see the picture below). This can be efficiently applied to both classification and regression problems. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/c6/Manual_decision_tree.jpg)\n",
    "<center> wikipedia </center>\n",
    "\n",
    "Mimicing the human decision logics, the decision tree recursively splits data into local regions. It is composed of decision nodes and terminal leaves. On each decision node, it finds a *test* function with a split threshold and the test function will outcome the branches. Starting from the root, if we traverse recursively to the leaf, we can reach the output label. \n",
    "\n",
    "\n",
    "## Practice \n",
    "\n",
    "**TODO:** Find a rule (if-statement) for the following classification boundaries (from Kdnuggets data mining course by Piatetsky and Parker) and write down your psedo code for it.  \n",
    "\n",
    "![](https://webpages.uncc.edu/mlee173/teach/itcs4156online/images/class/decision_tree.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Univariate Trees\n",
    "\n",
    "In each decision node, when the test function uses only one input feature, we call it as univariate tree. Let $x_k$ bs a $k$-th input dimension in a decision node $m$. If $x_k$ is discrete (ie. {red, green, blue}), the test function will output the corresponding branches to split (ie. three branches). If $x_k$ is continuous, we will need to choose threshold values $\\theta_m$ to build a test function\n",
    "\n",
    "$$\n",
    "  f_m(\\xv): x_k > \\theta_m,\n",
    "$$\n",
    "which will result in binary split. As we practiced above, the leaf nodes will form a hyperrectangles for classificaiton. \n",
    "\n",
    "Then, how can we build those three is the question that we have for a learning problem.\n",
    "There can be multiple trees even with zero errors. One of simple choice that we can make is the tree with lowest complexity (ie. with the smallest number of nodes). Finding the smallest tree is NP-complete (Quinlan 1986), so we use local search based on heuristics. \n",
    "\n",
    "The greedy learning algorithm can be outlined as\n",
    "\n",
    "1. find a feature for decision making\n",
    "2. find a split threshold for the test condition\n",
    "3. check stopping criteria\n",
    "4. create children and recursively repeat 1-4. \n",
    "\n",
    "Here the stopping condition can be when we cannot split anymore, which means a leaf node is created and labeled. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Classification Trees\n",
    "\n",
    "Let us focus the application of decision trees on classification problems. For learning, we need to consider how we can select a feature or a threshold for a decision node. For this, we need to measure the goodness of a split, which is called *impurity measure*. \n",
    "Here summarizes the popular impurity measures. \n",
    "\n",
    "1. Misclassification Rate\n",
    "$$\n",
    "E_R = \\frac{| \\{i: y_i^R \\ne t_i, x_i \\in R \\} | }{|\\{ i: x_i \\in R \\}| }\n",
    "$$\n",
    "2. Information Gain (Cross-entropy)\n",
    "$$\n",
    "I = -\\sum_{i=1}^N p_i \\log_2 p_i \\\\\n",
    "I_G = I_{parent} - I_{children} \n",
    "$$\n",
    "3. Gini Impurity (Breiman et al. 1984)\n",
    "$$\n",
    "I_G = \\sum_{i=1}^N p_i (1 - p_i) = \\sum_{i=1}^N p_i - \\sum_{i=1}^N p_i^2 = 1 - \\sum_{i=1}^N p_i^2\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSA3WdyoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110f3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test data similar to the practice\n",
    "\n",
    "# 25 data samples from X1 - X3\n",
    "X1 = np.random.rand(7,2) * 2\n",
    "X1[:, 0] += 5 \n",
    "X1[:, 1] = X1[:, 1] * 3 + 2 \n",
    "\n",
    "X2 = np.random.rand(15,2) * 5 \n",
    "X2[:, 1] += 5 \n",
    "\n",
    "X3 = np.random.rand(3,2) + 1 \n",
    "X3[:, 1] += 1 \n",
    "\n",
    "# 10 data samples for X4\n",
    "X4 = np.random.rand(10,2) * 3\n",
    "X4[:, 0] += 2.5 \n",
    "X4[:, 1] += 2 \n",
    "\n",
    "# input data  \n",
    "X = np.vstack((X1, X2, X3, X4))\n",
    "\n",
    "# target label\n",
    "T = np.zeros(35)\n",
    "T[25:] = 1\n",
    "# pick randomly from X1 and X2 as different class for noise \n",
    "T[[5, 15]] = 1\n",
    "\n",
    "\n",
    "plt.plot(X[T==0,0], X[T==0,1], 'bo')\n",
    "plt.plot(X[T==1,0], X[T==1,1], 'ro')\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sample data, we first create function to compute the impurity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute cross entropy\n",
    "def entropy(t):\n",
    "    _, c = np.unique(t, return_counts=True)\n",
    "    probs = c / len(t)\n",
    "    res = 0. \n",
    "    for p in probs:\n",
    "        res += -p * np.log2(p)\n",
    "    return res\n",
    "\n",
    "\n",
    "# information gain for given cut at the index, k \n",
    "def info_gain(t, k):\n",
    "    if k == 0 or k == len(t):\n",
    "        return 0.\n",
    "    \n",
    "    Ip = entropy(t) # parent\n",
    "    Icl = entropy(t[:k])  # left\n",
    "    Icr = entropy(t[k:])  # right\n",
    "    \n",
    "    p_l = len(t[:k]) / len(t)\n",
    "    p_r = 1 - p_l\n",
    "    return Ip - p_l * Icl - p_r * Icr\n",
    "\n",
    "# increasing threshold cut, compute the measures...\n",
    "def impurity(t):\n",
    "    return [info_gain(t, k) for k in range(1,len(t))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the impurity measure, recursively find split parent into child to construct a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-4\n",
    "\n",
    "# find threshold and its impurity measure\n",
    "def find_thres(x, t):\n",
    "    best = None\n",
    "    sorted_i = np.argsort(x)\n",
    "    values = impurity(t[sorted_i])\n",
    "    k = np.argmax(values)\n",
    "    thres = np.mean(x[sorted_i][k:k+2])\n",
    "    return (thres, values[k])\n",
    "\n",
    "def split(X, t, root=0, max_depth=4):\n",
    "    if root / 2 >= max_depth:\n",
    "        return\n",
    "    \n",
    "    # when there is only one element in the target, stop \n",
    "    if len(np.unique(t)) == 1:\n",
    "        return t\n",
    "    \n",
    "    # 1. find a feature for decision making\n",
    "    measures = np.max([impurity(t[np.argsort(X[:, j])]) for j in range(X.shape[1])], 1)\n",
    "    j = np.argmax(measures)\n",
    "    \n",
    "    # if max is close to zero, return \n",
    "    if measures[j] < eps:\n",
    "        return t\n",
    "    \n",
    "    # 2. find a split threshold for the test condition\n",
    "    best_thres, best_val = find_thres(X[:, j], t) \n",
    "    \n",
    "    # assuming binary tree\n",
    "    left = X[:,j] < best_thres\n",
    "    right = X[:,j] >= best_thres\n",
    "    \n",
    "    # BUILD A TREE STRUCTURE HERE\n",
    "    res = {}\n",
    "    res[(root, \"L\", j, best_thres)] = split(X[left], t[left], 2 * root + 1, max_depth)\n",
    "    res[(root, \"R\", j, best_thres)] = split(X[right], t[right], 2 * root + 2, max_depth)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the decision tree on the data, we achive the tree as shown in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,\n",
       "  'L',\n",
       "  1,\n",
       "  4.1370699786970038): {(1,\n",
       "   'L',\n",
       "   0,\n",
       "   2.2755893533553113): array([ 0.,  0.,  0.]), (1,\n",
       "   'R',\n",
       "   0,\n",
       "   2.2755893533553113): None},\n",
       " (0, 'R', 1, 4.1370699786970038): {(2, 'L', 0, 2.7885215231257345): None,\n",
       "  (2, 'R', 0, 2.7885215231257345): None}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = split(X, T, 0, 2)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursively traversing the tree, we plot the data and decision boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'L', 1, 4.1370699786970038), (0, 'R', 1, 4.1370699786970038)]\n",
      "[(1, 'L', 0, 2.2755893533553113), (1, 'R', 0, 2.2755893533553113)]\n",
      "[(2, 'L', 0, 2.7885215231257345), (2, 'R', 0, 2.7885215231257345)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1181cbcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[T==0,0], X[T==0,1], 'bo')\n",
    "plt.plot(X[T==1,0], X[T==1,1], 'ro')\n",
    "\n",
    "xmin, xmax = np.min(X[:, 0]), np.max(X[:, 0])\n",
    "ymin, ymax = np.min(X[:, 1]), np.max(X[:, 1])\n",
    "\n",
    "def traverse(tr, xmin, xmax, ymin, ymax):\n",
    "    if not isinstance(tr, dict):\n",
    "        return\n",
    "    \n",
    "    keys = list(tr.keys())\n",
    "    print(keys)\n",
    "    _, _, j, thres = keys[0]\n",
    "    if j == 1:\n",
    "        #print(f\"plot y {thres} {xmin} {xmax} {ymin} {ymax}\")\n",
    "        plt.plot([xmin, xmax], [thres, thres], '-')\n",
    "        traverse(tr[keys[0]], xmin, xmax, ymin, thres) # left\n",
    "        traverse(tr[keys[1]], xmin, xmax, thres, ymax) # right\n",
    "    elif j == 0:\n",
    "        #print(f\"plot x {thres} {xmin} {xmax} {ymin} {ymax}\")\n",
    "        plt.plot([thres, thres], [ymin, ymax], '-')\n",
    "        traverse(tr[keys[0]], xmin, thres, ymin, ymax) # left\n",
    "        traverse(tr[keys[1]], thres, xmax, ymin, ymax) # right\n",
    "    \n",
    "        \n",
    "traverse(tree, xmin, xmax, ymin, ymax)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Regression Trees\n",
    "\n",
    "A regression tree can be constructed in the same manner as a classification tree.\n",
    "However, for regression trees, we need to modify the impurity measure appropriate for regression problems. We can simply replace previous information gain to standard deviation reduction and build a regression tree as in the scikit-learn figure.\n",
    "When constructing a tree, we calculate the final value on a leaf note with the *average*. \n",
    "For example, please take a look at this (http://chem-eng.utoronto.ca/~datamining/dmc/decision_tree_reg.htm).\n",
    "\n",
    "* Standard Deviation Reduction:\n",
    "$$\n",
    "\\sigma_R = \\sigma_{parent} - \\sigma_{children}\n",
    "$$\n",
    "\n",
    "\n",
    "![](http://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Multivariate Trees\n",
    "\n",
    "For a univariate tree, we use only one feature variable at each decision node for a split. In a multivarate tree, all the input features can be used. Thus, this becomes more general approach and the decision function can be defined as a linear function with a threshold $\\tau_m$ at the node $m$ as\n",
    "$$\n",
    "b_m(\\xv) = \\wv_m^\\top \\xv - \\tau_m> 0. \n",
    "$$\n",
    "\n",
    "Because of an exhaustive search for vast amount of possible hyperplanes, it requires heavy computation (Murthy et al. 1994). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random forest is an ensemble method that uses multiple trees (a bag of trees) for better classification or regression. With training data, it training a preset number of trees and when making a prediction, it votes for final decision from multiple decision tree predictions.\n",
    "Typically, we refer to a decision forest in general and random forest when we training each tree with a random subset of the input features--this has increased overall accuracy significantly. \n",
    "\n",
    "![](https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-017-1578-z/MediaObjects/12859_2017_1578_Fig1_HTML.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] R. Quinlan, \"Learning efficient classification procedures\", Machine Learning: an artificial intelligence approach, Michalski, Carbonell & Mitchell (eds.), Morgan Kaufmann, 1983, p. 463-482.\n",
    "\n",
    "[2] Quinlan, J. R. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, 1993.\n",
    "\n",
    "[3] Breiman, Leo; Friedman, J. H.; Olshen, R. A.; Stone, C. J. (1984). Classification and regression trees. Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

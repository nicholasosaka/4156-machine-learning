{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    " \\newcommand{\\wv}{\\mathbf{w}}\n",
    " \\newcommand{\\yv}{\\mathbf{y}}\n",
    " \\newcommand{\\zv}{\\mathbf{z}}\n",
    " \\newcommand{\\uv}{\\mathbf{u}}\n",
    " \\newcommand{\\vv}{\\mathbf{v}}\n",
    " \\newcommand{\\Chi}{\\mathcal{X}}\n",
    " \\newcommand{\\R}{\\rm I\\!R}\n",
    " \\newcommand{\\sign}{\\text{sign}}\n",
    " \\newcommand{\\Tm}{\\mathbf{T}}\n",
    " \\newcommand{\\Xm}{\\mathbf{X}}\n",
    " \\newcommand{\\Zm}{\\mathbf{Z}}\n",
    " \\newcommand{\\I}{\\mathbf{I}}\n",
    " \\newcommand{\\Um}{\\mathbf{U}}\n",
    " \\newcommand{\\Vm}{\\mathbf{V}} \n",
    " \\newcommand{\\muv}{\\boldsymbol\\mu}\n",
    " \\newcommand{\\Sigmav}{\\boldsymbol\\Sigma}\n",
    " \\newcommand{\\Lambdav}{\\boldsymbol\\Lambda}\n",
    "$\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "\n",
    "In this module, let us learn how we use probability in learning. \n",
    "Naive Bayes is a simple classifier that uses \"naive\" assumption on the conditional independence.\n",
    "As a fast, multi-class classifier, it has been used for real-time prediction, text classification, spam filtering, sentiment analysis, and recommendation systems. \n",
    "Let us start from the quick review of probability theory to Naive Bayes algorithm. \n",
    "\n",
    "As we reviewed in Week 2, \n",
    "* for two (or more) random variables, a **joint probability** $p(X, Y)$ calculates the likelihood of two (or more) random envets occur at the same time. \n",
    "* A **conditional probability** $p(Y \\mid X)$ measures the chance of an event ($Y$) occurs given another event ($X$) has occured. \n",
    "* We can **marginalize** the joint probability for a subset of random variables without referencing the other:\n",
    "$$\n",
    "   p(X) = \\sum_Y p(X, Y). \n",
    "$$\n",
    "* Given the definition of conditional probability, \n",
    "$$\n",
    "  p(Y \\mid X) = \\frac{p(X, Y)}{p(X)},  \n",
    "$$\n",
    "we can write the **product rule**\n",
    "$$\n",
    "  p(X, Y) = p(Y \\mid X) p(X). \n",
    "$$\n",
    "* When the two event $X$ and $Y$ are independent, $p(Y \\mid X) = p(Y)$ because the chance $Y$ occurs is not relevant to $X$. This imiplies the product rule:\n",
    "$$\n",
    "  p(X, Y) = p(X) p(Y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability for Classification\n",
    "\n",
    "Let $x$ be our input data and $y$ be target class label. We can formulate our classification problem to measure the chance to achive the correct label $y$ given the input $x$. That is, a conditional probability \n",
    "$$\n",
    "p(y \\mid x).\n",
    "$$\n",
    "If we learn the distribution, we can make a prediction by picking a class label that has the maximum conditional probability. This is called the *Bayes-optimal* classifier. \n",
    "\n",
    "*Discriminative models* learn directly estimate $p(y \\mid x)$ while *generative models* use the model for the likelihood $p(x \\mid y)$ to get the posterior using Bayes rule. \n",
    "\n",
    "### Bayes Rule\n",
    "\n",
    "The joint probability \n",
    "$$\n",
    "p(X, Y) = p(Y, X). \n",
    "$$\n",
    "From the product rule, \n",
    "$$\n",
    "\\begin{align}\n",
    "p(X, Y) = p(X \\mid Y) p(Y), \n",
    "p(Y, X) = p(Y \\mid X) p(X). \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\therefore p(X \\mid Y) p(Y) = p(Y \\mid X) p(X)\n",
    "$$\n",
    "\n",
    "This leads us to Bayes rule:\n",
    "$$\n",
    "    p(Y \\mid X)  = \\frac{p(X \\mid Y) p(Y)}{p(X)}\n",
    "$$\n",
    "\n",
    "Remeber the terminology \n",
    "* posterior: $p(Y \\mid X)$\n",
    "* likelihood: $p(X \\mid Y)$\n",
    "* prior: $p(Y)$\n",
    "* evidence: $p(X)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum a posteriori\n",
    "\n",
    "The maximum a posteriori (MAP) estimates the mode of the posterior distribution:  \n",
    "$$\n",
    "  y_{MAP} = \\arg \\max_Y p(Y \\mid X) = \\arg \\max_Y \\frac{p(X \\mid Y) p(Y)}{p(X)} = \\arg \\max_Y p(X \\mid Y) p(Y)\n",
    "$$\n",
    "\n",
    "If we assume the prior distribution $p(Y)$ to be uniform or ignore it for a simple solution, we obtain the maximum likelihood: \n",
    "$$\n",
    "  y_{ML} = \\arg \\max_Y p(X \\mid Y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes models $P(X \\mid Y)$ with aforementioned conditional independence. \n",
    "That is, the input features are independent, given the class label. \n",
    "\n",
    "#### Naive Bayes Assumption\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\Xm \\mid Y) &= P(\\xv_1, \\xv_2, \\ldots, \\xv_N \\mid Y) \\\\\n",
    "              &=  P(\\xv_1 \\mid Y) P(\\xv_2 \\mid T, \\xv_1) P(\\xv_3 \\mid T, \\xv_1, \\xv_2) \\cdots P(\\xv_N \\mid T, \\xv_1, \\ldots, \\xv_N)\\\\\n",
    "              &= P(\\xv_1 \\mid Y) P(\\xv_2 \\mid Y) \\cdots P(\\xv_N \\mid Y) \\\\\n",
    "              &= \\prod_i^N P(\\xv_i \\mid Y)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Using the likelihood model, we can make a prediction using the following decision rule:\n",
    "$$\n",
    "  y_{NB} = \\arg \\max_Y p(X \\mid Y) p(Y) = \\arg \\max_Y \\prod_i^N P(\\xv_i \\mid Y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Naive Bayes \n",
    "\n",
    "Training process computes the prior and likelihood as below from the training data. \n",
    "\n",
    "$$\n",
    "\\hat{P}(y) = \\frac{\\vert \\{i: y = y_i \\} \\vert} {N}, \\\\\n",
    "\\hat{P}(\\xv_i \\mid y) = \\frac{\\hat{P}(\\xv_i, y)}{\\hat{P}(y)} = \\frac{ \\vert \\{i: \\xv = \\xv_i, y = y_i \\} \\vert \\mathbin{/} N}{ \\vert \\{i: y = y_i \\} \\vert \\mathbin{/} N } = \\frac{\\vert \\{i: \\xv = \\xv_i, y = y_i \\} \\vert}{\\vert \\{i: y = y_i \\} \\vert}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Weather\n",
    "\n",
    "Let us play with this simple weather data as in the table. For each input feature, we want to train a classifier that predicts the binary lable \"class.\"\n",
    "\n",
    "\n",
    "Outlook | Temperature | Humidity | Windy | Class\n",
    "--|--|--|--|--\n",
    "sunny | hot | high | false | -\n",
    "sunny | hot | high | true | - \n",
    "overcast | hot | high | false | +\n",
    "rain | mild | high | false | + \n",
    "rain | cool | normal | false | + \n",
    "rain | cool | normal | true | - \n",
    "overcast | cool | normal | true | +\n",
    "sunny | mild | high | false | -\n",
    "sunny | cool | normal | false | + \n",
    "rain | mild | normal | false | +\n",
    "sunny | mild | normal | true | + \n",
    "overcast | mild | high | true | + \n",
    "overcast | hot | normal | false | + \n",
    "rain | mild | high | true | - \n",
    "sunny | cool | high | true | ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writefile magic command in Jupyter Notebook creates a file named weather.csv with the listed content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weather.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile weather.csv\n",
    "Outlook, Temperature, Humidity, Windy, Class\n",
    "sunny, hot, high, false, -1\n",
    "sunny, hot, high, true, -1 \n",
    "overcast, hot, high, false, 1\n",
    "rain, mild, high, false, 1 \n",
    "rain, cool, normal, false, 1 \n",
    "rain, cool, normal, true, -1 \n",
    "overcast, cool, normal, true, 1\n",
    "sunny, mild, high, false, -1\n",
    "sunny, cool, normal, false, 1 \n",
    "rain, mild, normal, false, 1\n",
    "sunny, mild, normal, true, 1 \n",
    "overcast, mild, high, true, 1 \n",
    "overcast, hot, normal, false, 1 \n",
    "rain, mild, high, true, -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>false</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>true</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>false</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook  Temperature  Humidity   Windy   Class\n",
       "0      sunny          hot      high   false      -1\n",
       "1      sunny          hot      high    true      -1\n",
       "2   overcast          hot      high   false       1\n",
       "3       rain         mild      high   false       1\n",
       "4       rain         cool    normal   false       1\n",
       "5       rain         cool    normal    true      -1\n",
       "6   overcast         cool    normal    true       1\n",
       "7      sunny         mild      high   false      -1\n",
       "8      sunny         cool    normal   false       1\n",
       "9       rain         mild    normal   false       1\n",
       "10     sunny         mild    normal    true       1\n",
       "11  overcast         mild      high    true       1\n",
       "12  overcast          hot    normal   false       1\n",
       "13      rain         mild      high    true      -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv file\n",
    "df = pd.read_csv(\"weather.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the each feature using value_counts command in pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunny       5\n",
      "rain        5\n",
      "overcast    4\n",
      "Name: Outlook, dtype: int64\n",
      " mild    6\n",
      " hot     4\n",
      " cool    4\n",
      "Name:  Temperature, dtype: int64\n",
      " high      7\n",
      " normal    7\n",
      "Name:  Humidity, dtype: int64\n",
      " false    8\n",
      " true     6\n",
      "Name:  Windy, dtype: int64\n",
      " 1    9\n",
      "-1    5\n",
      "Name:  Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the dataframe into two for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rain</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rain</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>normal</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook  Temperature  Humidity   Windy   Class\n",
       "2   overcast          hot      high   false       1\n",
       "3       rain         mild      high   false       1\n",
       "4       rain         cool    normal   false       1\n",
       "6   overcast         cool    normal    true       1\n",
       "8      sunny         cool    normal   false       1\n",
       "9       rain         mild    normal   false       1\n",
       "10     sunny         mild    normal    true       1\n",
       "11  overcast         mild      high    true       1\n",
       "12  overcast          hot    normal   false       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpos = df[df.iloc[:, -1] == 1]\n",
    "dfneg = df[df.iloc[:, -1] == -1]\n",
    "dfpos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here prints the value_counts for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "overcast    4\n",
      "rain        3\n",
      "sunny       2\n",
      "Name: Outlook, dtype: int64\n",
      " mild    4\n",
      " cool    3\n",
      " hot     2\n",
      "Name:  Temperature, dtype: int64\n",
      " normal    6\n",
      " high      3\n",
      "Name:  Humidity, dtype: int64\n",
      " false    6\n",
      " true     3\n",
      "Name:  Windy, dtype: int64\n",
      "1    9\n",
      "Name:  Class, dtype: int64\n",
      "_______________________________________\n",
      "sunny    3\n",
      "rain     2\n",
      "Name: Outlook, dtype: int64\n",
      " hot     2\n",
      " mild    2\n",
      " cool    1\n",
      "Name:  Temperature, dtype: int64\n",
      " high      4\n",
      " normal    1\n",
      "Name:  Humidity, dtype: int64\n",
      " true     3\n",
      " false    2\n",
      "Name:  Windy, dtype: int64\n",
      "-1    5\n",
      "Name:  Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for hdf in [dfpos, dfneg]:\n",
    "    print(\"_______________________________________\")\n",
    "    for col in hdf.columns:\n",
    "        print(hdf[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** First, compute the priors using the number of samples for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35714286,  0.64285714])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compute the prior to  \n",
    "priors = np.array([dfneg.shape[0], dfpos.shape[0]]) / df.shape[0]\n",
    "priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We use Python dictionary to store the conditional probabilities for each feature given the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: {'cool': 0.20000000000000001,\n",
       "  'false': 0.40000000000000002,\n",
       "  'high': 0.80000000000000004,\n",
       "  'hot': 0.40000000000000002,\n",
       "  'mild': 0.40000000000000002,\n",
       "  'normal': 0.20000000000000001,\n",
       "  'overcast': 0.0,\n",
       "  'rain': 0.40000000000000002,\n",
       "  'sunny': 0.59999999999999998,\n",
       "  'true': 0.59999999999999998},\n",
       " 1: {'cool': 0.33333333333333331,\n",
       "  'false': 0.66666666666666663,\n",
       "  'high': 0.33333333333333331,\n",
       "  'hot': 0.22222222222222221,\n",
       "  'mild': 0.44444444444444442,\n",
       "  'normal': 0.66666666666666663,\n",
       "  'overcast': 0.44444444444444442,\n",
       "  'rain': 0.33333333333333331,\n",
       "  'sunny': 0.22222222222222221,\n",
       "  'true': 0.33333333333333331}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likelihood \n",
    "# P(X | +)\n",
    "\n",
    "likeli = {1: {}, -1: {}}\n",
    "for hdf in [dfpos, dfneg]:\n",
    "    for col in df.columns[:-1]:\n",
    "        Nh = hdf.shape[0]\n",
    "        for val in df[col].unique():\n",
    "            likeli[hdf.iloc[0, -1]][val.strip()] = np.sum(hdf[col] == val) / Nh\n",
    "\n",
    "likeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Using the conditional independence, compute the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: compute the likelihood estimate assuming the function has access to the global variable, likeli \n",
    "def likelihood(outlook, temp, humid, wind, target):\n",
    "    return likeli[target][outlook] * likeli[target][temp] * \\\n",
    "        likeli[target][humid] * likeli[target][wind]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Now, compute likelihood $\\times$ prior, $p(X \\mid Y) p(Y)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0205714285714 0.00529100529101\n"
     ]
    }
   ],
   "source": [
    "# discriminant for the example target: sunny, cool, high, true\n",
    "neg_p = likelihood('sunny', 'cool', 'high', 'true', -1) * priors[0]\n",
    "pos_p = likelihood('sunny', 'cool', 'high', 'true', 1) * priors[1]\n",
    "\n",
    "print(neg_p, pos_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the posterior, we can normalize the value by dividing the values by the sume of them. So, when it is sunny, cool, highly humid, and windy, it is likely to be classified to \"positive\" with 79% of chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79541735  0.20458265]\n"
     ]
    }
   ],
   "source": [
    "# normalize    \n",
    "print(np.array([neg_p, pos_p]) / np.sum([neg_p, pos_p]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far, we have been played with Naive Bayes classifer. We can summarize pros and cons of the classifier as follows:\n",
    "\n",
    "\n",
    "### Pros\n",
    "- easy and fast to predict\n",
    "- *when Naive Bayes assumption holds*, it works well\n",
    "- performs well with categorical variables\n",
    "\n",
    "### Cons\n",
    "\n",
    "- *Zero Frequency*: no observed categorical values will have 0 probability\n",
    "  - Worse when data is sparse\n",
    "- Bad estimator: the probability outputs are not to be taken too seriously\n",
    "- Naive Bayes assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Laplacian Smoothing\n",
    "\n",
    "As listed above, *Zero Frequency* problem can be an issue with the original Naive Baye. \n",
    "Even in the simple example above, we can observe \n",
    "$$\n",
    "P(Outlook = overcast \\mid -) = 0.\n",
    "$$\n",
    "\n",
    "\n",
    "When the data is sparse, we have many zero conditional probabilities, \n",
    "$$P(X = sparse \\mid T) = 0.$$\n",
    "\n",
    "This can cause computation errors as in this sample case: \n",
    "\n",
    "$$\n",
    "P( Y=red \\mid x ) = \\frac{\\prod_i P(x_i \\mid Y=red) P(Y = red)}{ \\sum_k^{colors} \\Big( \\prod_i P(x_i \\mid Y=k) P(Y=k) \\Big)} = \\frac{0}{0}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remedy\n",
    "Laplacian smoothing fixes the zero frequency problem by simply adding 1 to the numerator, and $k$ the number of categories to the denominator. \n",
    "\n",
    "\n",
    "$$\n",
    "P(X = sparse \\mid Y) = \\frac{}{} = \\frac{\\vert \\{i: x = x_i, y = y_i \\} \\vert + 1}{\\vert \\{i: y = y_i \\} \\vert + k}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: {'cool': 0.25,\n",
       "  'false': 0.42857142857142855,\n",
       "  'high': 0.7142857142857143,\n",
       "  'hot': 0.375,\n",
       "  'mild': 0.375,\n",
       "  'normal': 0.2857142857142857,\n",
       "  'overcast': 0.125,\n",
       "  'rain': 0.375,\n",
       "  'sunny': 0.5,\n",
       "  'true': 0.5714285714285714},\n",
       " 1: {'cool': 0.33333333333333331,\n",
       "  'false': 0.63636363636363635,\n",
       "  'high': 0.36363636363636365,\n",
       "  'hot': 0.25,\n",
       "  'mild': 0.41666666666666669,\n",
       "  'normal': 0.63636363636363635,\n",
       "  'overcast': 0.41666666666666669,\n",
       "  'rain': 0.33333333333333331,\n",
       "  'sunny': 0.25,\n",
       "  'true': 0.36363636363636365}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conditional probabilities with Laplacian Smoothing\n",
    "# P(X | +)\n",
    "\n",
    "likeli = {1: {}, -1: {}}\n",
    "for hdf in [dfpos, dfneg]:\n",
    "    for col in df.columns[:-1]:\n",
    "        cats = df[col].unique()\n",
    "        Nh = hdf.shape[0] + len(cats) # k = the number of categories\n",
    "        for val in cats:\n",
    "            likeli[hdf.iloc[0, -1]][val.strip()] = (np.sum(hdf[col] == val) + 1) / Nh\n",
    "\n",
    "likeli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
